<div	style="font-size:16pt">
<div	style="width:408pt;color:#000080;background-color:#E0FFFF80;font-family:helvetica;border-radius:5pt;text-align:right">
	<a style="font-size:24pt">Floating Point New Platinum Standard</a><br>
	<a style="font-size:15pt">192-bit single-instruction floating operations</a></div>

<p>
RTA1 has moved <a href="rta.html#simd_fp">192-bit floating binary operation</a> into SIMD space, programming examples <a href="rta.html#fpexa">fa</a> <a href="rta.html#fpexan">fan</a> <a href="rta.html#fpexm">fm</a> <a href="rta.html#fpexd">fd</a>

<p>
The move is primarily a performance initiative

<p>
192-bit floating arithmetic has been present as library sequences of several 96-bit floating instructions

<p>
Each 192-bit operation is now a single instruction. See <a href="http://172.29.7.7/q_a.html?q_a.html#fp192">Q & A: 192-Bit Single-Instruction Floating Operations</a>

<p>
192-bit single-instruction floating operation is in SIMD space because SIMD happens in the internal stack, the simplest place to load operands eight data words in size

<p>
96-bit floating point is available in SIMD space and in regular instruction space

<p>
In all cases source-2 operands may be in memory or in registers

<p>
The internal stack is a register array which can hold twelve-plus * 192-bit floating operands, depending what else is in that stack

<p>
All application threads start up ready configured to operate one SIMD object on the internal stack top. The M in SIMD means multiple. Multiple data points take a <a href="rta.html#simd_c">one-time reconfiguration sequence</a> two instructions long

<p>
Performance leaps upward where a single instruction replaces a library call. Additionally the needle-fine precision is in a small number of cases a single bit sharper because fewer instructions are executed

<p>
Here's what happens when you divide two million by three fourteen times over. And then multiply the result by three fourteen times over

<pre>

	$ fp -QU 172.29.7.8
	2000000 / 3, 14
	<a style="color:#0000FF">+4.181503162575379434823851043149140209773469e-1</a>
	+4.181503162575379434823851043149140209773469e-1 * 3, 14
	<a style="color:#0000FF">+2.000e+6</a>

</pre>

RTA1 SIMD also does 96-bit floating point with up to 25 * 96-bit operands in the internal stack

<p>
There are advantages which may not be obvious in immense precision

<p>
The divisor in the following step looks short and simple, but it could never be adequately represented in 96 bits

<p>
&plusmn; exponents in a range as close as [ e-1 .. e+31 ] cause the mantissa to exceed 72 bits, because text or language exponents are &plusmn;powers<sup>10</sup> represented by multiplying / dividing the value to derive a mantissa and binary scale

<pre>

	$ fp -QU 172.29.7.7
	3.666666999999333333666666999999333333666666e1100000 / 3e-150000
	<a style="color:#0000FF">+1.222222333333111111222222333333111111222222e+1250000</a>

</pre>

The large exponent space removes all realistic restrictions from floating values and will only fault if wrong data is inadvertantly computed

<p>
Both 96-bit and 192-bit RTA1 floating arithmetic have a 23-bit mid-pointed exponent giving a range of scale &plusmn;1262611<sub>10</sub>

<p>
Mantissa size is 72 bits or 144 bits

</div>

