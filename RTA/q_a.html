<html>
<div    style="font-size:15pt">

<center>

<h1>RTA1: Q & A</h1>


<i>
Copyright Tim Cox, 2012<br>
This document is part of the RTA1 Processor Programmable Architecture Specification<br>
The RTA1 Architecture is freeware licensed with the GNU General Public Licence Version 3<br>
The same licence encompasses all accompanying software and documentation <br>
The full licence text is included with these materials<br>
See also the licensing notice at the foot of this document
</i>

</center>

<ol>
	<li><a href="#fp">why so much effort for floating point?</a></li>
	<ol>
		<li><a href="#how_sofp">how so?</a></li>
                <li><a href="#not_ieee">why isn't it IEEE754 floating point?</a></li>
                <li><a href="#large_96">isn't 96 bits too large for some things?</a></li>
		<li><a href="#not_triadic"/>why isn't it triadic floating operation?</a></li>
		<li><a href="#fp192">how is 192-bit floating arithmetic done? Why?</a></li>
	</ol>
	<li><a href="#bytes">can RTA1 access bytes efficiently?</a></li>
	<ol>
		<li><a href="#bit_stream">bit-stream channels</a></li>
                <li><a href="#hw_tw">integer instruction word/halfword/thirdword select</a></li>
		<li><a href="#pixels_large">UTF-32, pixels, large and small bytes<a></li>
	</ol>
	<li><a href="#stackspace">does the internal stack run out of space?</a></li>
	<ol>
		<li><a href="#structured_real">structured realtime in the internal stack</a></li>
		<li><a href="#recursion">recursive programming and zero-net internal stack</a></li>
	</ol>
	<li><a href="#proswip">does RTA1 switch context quickly?</a></li>
</ol>


<br><br>
<a      href="rta.html#sim_d"
	style="text-decoration:none;color:#FF0000;font-family:courier;font-size:14pt;width:420pt">
	...breaking.news...RTA1 has 100 Accumulators...</a>
<a	href="rta.html#sim_d"
	style="text-decoration:none;color:#000000;font-size:12pt;font-family:courier;
	left:430pt;width:390pt;position:absolute">
		An instruction repeat model using as accumulators<br>
		some or all of the 104 internal stack registers<br>
		is now rolled out initially for floating point...</a><br><br>


<a	name="fp"/>
<h2>1: why so much effort for floating point?</h2>

Because it's the best way of doing large fixed-point arithmetic

<a	name="how_sofp"/>
<h3>1.1: how so?</h3>

<p>
Many very small &mu;Cs acquire a coprocessor or an emulation
library quite early in their product history

<p>
They don't need big arithmetic except when they do

<p>
RTA1 starts with big number capacity that is simple
to implement and needs no extras

<p>
The crunch really comes when you have multipliers or
divisors longer than the word size

<p>
<b>Extensive testing of integer calulation supported by RTA1 96-bit floating-point has secured exact integer results including multiplication, division and remainder</b>

<p>
<b>Rounding policy is programmable per thread on RTA1 and should be set at no rounding when used for large integers,
because so long as values are in integer range there is no truncation to compensate</b>

<p>
Floating point is 100% deterministic and integer-accurate
so long as the composite of significands is not larger
than the mantissa length

<p>
RTA1 floating-point is 100% deterministic
and integer-accurate with any overlap of multiplicand and
multiplier significands up to 72 bits in width

<p>
like a multiplicand 35 bits wide and multiplier 37 bits
wide, for example

<p>
and any dividend size up to 72 bits with any
divisor size up to 72 bits

	<div    style="color:0040FF">
	<blockquote>

	<b>Accuracy in Floating Binary</b><br><br>

	For some 60 years, financial applications have used integers with imputed
	decimal scales maintained by software. The results of doing this are 100% precise

	<p>
	Suppliers have also produced floating decimal hardware to make the alignment
	of decimal scales less laborious while avoiding certain fractional roundings
	of floating binary. However this was never necessary

	<p>
	Fractional roundings in floating binary only ever happen in fractional values,
	or in values of astronomical magnitude where the low-order end of the integer
	is truncated and rounded.

	<p>
	Numbers expressing money values can be kept in the range of expressible integers

	<p><b>
	But financial applications have fractions called cents or pence or rappen
	don't they?</b>

	<p>
	They don't have to have. Numbers which have a fixed scale are not really
	floating-point. They are fixed-point with a known bias. That's how fixed
	point arithmetic could do financial stuff for 60 years

	<p>
	RTA1's 72-bit mantissa can be used to represent all of 21 decimal numerals.
	Like 18 columns of cents and three columns of thousandths of a cent. Any
	rounding is decided by financial policy instead of by machine architecture
	(There is always rounding in financial applications whatever sort of machine
	they run on. Especially when exchange rates or interest rates apply)

	<p><b>
	But why use floating binary numbers to represent large integers to represent
	values with a fixed decimal scale?</b>

	<p>
	Alignment between operands with differing decimal scales is effortless
	in floating point. Each arithmetic function is also a single instruction
	where integer arithmetic on large numbers may take some manipulation 

        <p>
        An overflow from integer number range is visible in the binary exponent
	which would exceed midpoint + mantissa size

	<p><b>
	Why did anyone think floating binary is vague?</b>

	<p>
	Partly because of human confusion. There are a very few avenues through
	the <i>fractional</i> number space where decimal and binary don't quite
	represent each other, but they come very close even in those cases. So
	close in fact that the difference mostly disappears on reconversion. In
	some very iterative calculations these representation gaps may accumulate
	something unwanted

	<p>
	To preserve the integrity of integers represented in floating numbers,
	it is also necessary to convert between text number string and floating
	binary with complete stringency

	<p>
	Obvious? Well some people writing sscanf and sprintf library have
	programmed some inaccuracy when adjusting for small numbers of decimal
	places. The mistake consists in adjusting the scale by multiplying by
	a fraction, which is an easy solution. The result is that you can key
	for example 3.000 into many computers and read back 2.999999

	<p>
	The accurate way involves applying small adjustments in decimal scale
	to an integer as far as possible, before changing the integer to floating.
	Part of an integer may be multiplied by the reciprocal of a downscale.
	That's how it's done on RTA1, and it all checks out

	<p>
	Similarly on redisplay, RTA1 library avoids any floating manipulation
	of a number in integer range. This avoids unnecessary rounding

	<p><b>
	Why did they develop those floating decimal machines, then?</b>

	<p>
	They may have thought that ignorantly-written library code was
	showing a geometric limitation of floating binary where it was only
	showing software mistakes
	
	<p>
	They may have thought library code for conversion between character
	string and floating binary must be laborious. But in RTA1 floating binary
	library, that code is shorter and quicker than the BCD and declet
	manipulations on floating decimal machines

	<p>
	And then, the internal logic of RTA1 floating binary architecture
	is infinitessimally simpler

	<p>
	This has been about calculating large integer values  reliably.
	Floating architectures do this

	<p>
	It's a different subject from representing subatomic-to-astronomic &plusmn; number scales

	<p>
	RTA1 does that like no other: &plusmn;1262611 decimal places
	</blockquote>
	</div>

<a	name="not_ieee"/>
<h3>1.2: why isn't it IEEE754 floating point?</h3>

RTA1 96-bit floating format has become necessary

<p>
The 72-bit mantissa and 23-bit exponent are the most useable size floating number

<p>
Any need for a longer mantissa is already met by teaming two values for a 144-bit mantissa

<p>
The 23-bit exponent will only fault on software error. Your thread gets notified

<p>
All clearly thought out and all present and available

<p>
Needs have grown beyond IEEE754 64-bit format, and attempts to stretch it haven't shown much conviction
and haven't future-proofed exponent size at all

<p>
64-bit format only has exponentiation equivalent to
about &plusmn;300 decimal places

<p>
The 80-bit format in some PC co-processors is a more
pragmatic number. It has 64 mantissa bits and exponentiation
equivalent to about &plusmn;5000 decimal places. This format
isn't IEEE754 either

<p>
The 128-bit IEEE754  also has exponentiation equivalent to
about &plusmn;5000 decimal places. This format doesn't seem to
be widely implemented

<p>
The 112-bit mantissa of the 128-bit IEEE754 format doesn't
look like future-proofing. It has only a 15-bit exponent

<p>
RTA1 has light years more number range, 72 mantissa bits and
exponentiation for &plusmn;1262611 decimal places. That's right,
&plusmn; one and one quarter million decimal places

<p>
Some applications could need more mantissa bits than 72. If any does,
RTA1 combines pairs of numbers for 192-bit floating arithmetic with an
effective mantissa of 144 bits and 23-bit exponent

<p>
72 mantissa bits represent up to 21 decimal digits, and 144 mantissa
bits represent up to 43 decimal digits

<p>
Additionally RTA1 96-bit floating format is simple to
implement in hardware. Ones-complement negative makes subtract the
same operation as add

<p>
Naturally RTA1 supports XDR externally, as far as XDR
reaches. Neither XDR nor other computers have a format
for the largest RTA1 numbers. Except for printable
ASCII format in XDR string items

<a	name="large_96"/>
<h3>1.3: isn't 96 bits too large for some things?</h3>

Yes. RTA1 computes 96-bit floating point but can
store in a 48-bit compressed floating format, if
that can represent your number

<p>
And there is always fixed-point arithmetic. 24-bit, 48-bit and 72-bit


<a	name="not_triadic"/>
<h3>1.4 why isn't it triadic floating operation?</h3>

Here a simple algorithm with five inputs is executed in five instructions, including
operand acquisition from storage
<pre>


$ masmx -ln r2xample.msm
MASMX 7r3
3/r2xample.msm
*EOF*
  :                            1        $path           ../def
  :                            2:       $include        rta.def
  :                            3        $path           ../language
  :                            4:       $include        stack.def
  :                            5:       $include        fpxpress.def
  :                            6        $path
  :                            7 $(0:0)
  :                            8
00:000000 B60040              +9 floating_algorithm*  $vector fp_routine
  :                            10
  :                            11 $(0:64)
  :                            12
  :                            13 fp_routine
                                        $head_far        params(one,    float           ;
                                                                two,    float           ;
  :                            16                               three,  float)
  :                            17
00:000040 4FF003              +18       $xqt_fp         one * 1.75*+1200000 * two / 3.0*-625000 - three
00:000041 770100              +18
00:000042 77F007              +18
00:000043 7F0104              +18
00:000044 6FF00B              +18
  :                            19
  :                            20
00:000045 3D0000              +21       fret            0
  :                            22
  :                            23       $do             $<256,$(0:256)
  :                            24
*EOF*
00:000100+7CD38BB7B396D7AA20B6E083
00:000104+2051D5B8447B77478A23F5F7
:$(00):000000:000108
r2xample.msm: object code 190 bytes: 0 errors: 0 undefined labels


</pre>


RTA1 multadic arithmetic reduces instruction
processing to just one instruction per operand

<p>
Load-store triadic architectures need twice so many
instructions as this to load operands and then compute

<p>
RTA1's seamless data hierarchy of registers and memory
produces irreducible code density and economy

<p>
There's nowhere further to go in straight-line architectures


<a	name="fp192">
<h3>1.5: how is 192-bit floating arithmetic done? why?</h3>

192-bit floating arithmetic is present in case specialist users need more mantissa
precision than 72 bits

<p>
Two 96-bit floating numbers are teamed to give an effective 144-bit mantissa.
This is effected when PSR flag <b>fp$r</b> is asserted. 96-bit floating instructions
then store two floating results

<p>
The first result is stored in registers a:b:mantissa2:mantissa3 and is not rounded.
The second result is rounded and stored in registers 8:9:10:11, and is nonzero if the total
result does not fit in 96 bits. This minor result or residue is added to the next part
of the sum. The exponent of the minor part is the major exponent minus 72 minus the
normalising count of the minor mantissa
<pre>

	ql	first_addend
	on	fp$r		. switch residue on in PSR
	fa	second_addend	. generate a major and a minor sum
	qs	sum
	off	fp$r		. switch residue off
	ql	first_addend+4
	fa	second_addend+4	. add the second parts
	fa	$residue	. add the minor sum of the first addition
	qs	sum+4

</pre>
PSR flag <b>fp$r</b> and minor result <b>$residue</b> (registers 8..11) are used the same way with all four arithmetic operations
<pre>

	ql	minuend
	on	fp$r		. switch residue on in PSR
	fan	subtrahend	. generate a major and a minor difference
	off	fp$r		. switch residue off
	qs	difference
	ql	minuend+4
	fan	subtrahend+4	. find the difference between the second parts
	fa	$residue	. add the minor difference from the major part
	qs	difference+4


	ql	multiplicand
	on	fp$r		. switch residue on in PSR
	fm	multiplier	. generate a major and a minor product
	off	fp$r		. switch residue off
	qs	product
	ql	multiplicand+4
	fm	multiplier	. multiply the second part
	fa	$residue	. add the minor product of the first multiplication
	qs	product+4


	ql	dividend
	on	fp$r		. switch residue on in PSR
	fd	divisor		. generate a major and a minor quotient
	off	fp$r		. switch residue off
	qs	quotient
	ql	dividend+4
	fd	divisor		. divide the second part
	fa	$residue	. add the minor quiotient from dividing the first part
	qs	quotient+4

</pre>
If a multiplier is larger than 96 bits it is necessary to multiply by its major and
minor parts and then sum the two 192-bit products. Minor result <b>$residue</b> is
required during both multiply passes and the subsequent add of two 192-bit products

<p>
If a divisor is larger than 96 bits, a long multiply by the 192-bit reciprocal of
the divisor is advised. A divisor is longer than 96 bits if the decimal exponent
equivalent is less than zero or more than 31:

<pre>


        $ fp -U
        remote application socket 3 bind state 0 F 2 NB 0 udconnect state 0
        3.666666999999333333666666999999333333666666e1100000 / 3e-150000
        send state 65
        recv state 55/35 +1.222222333333111111222222333333111111222222e+1250000


</pre>


<p>
When a series of operations is iterated on one 192-bit value a large number of times,
any accumulation of rounding effects, and any accumulating discontinuity between major
and minor numbers should be suppressed. This is achieved with an intermittent
super-normalisation of the value. Its major and minor parts are summed with <b>fp$r</b>
asserted. The largest possible part of the total value is consequently stored in the
major part in registers a:b:mantissa2:mantissa3. The resulting zero or nonzero minor
part is stored in registers 8:9:10:11
<pre>

	  ql	minuend		. operation sequence
	  on	fp$r
	  fan	subtrahend
	  qs	difference
	  off	fp$r
	  ql	minuend+4
	  fan	subtrahend+4
	  fa	$residue

	on	fp$r		. super-normalise sequence
	fa	difference
	qs	difference
	off	fp$r
	ql	$residue

	  qs	difference+4	. completion of operation sequence


</pre>


<a	name="bytes"/>
<h2>2: can RTA1 access bytes efficiently?</h2>

<a	name="bit_stream"/>
<h3>2.1: bit-stream channels</h3>

RTA1 bit-stream-channels are the most efficient handler of any architecture for
unaligned byte strings

<p>
RTA1 bit-stream-channels deliver any size data field to the application,
but read and write memory in 24-bit words

<p>
Very unaligned network protocols like SNMP run more efficiently on RTA1
than anywhere else

<p>
Please see also <a href="#pixels_large">2.3: UTF-32, pixels, large and small Bytes</a>
and <a href="checkli.html">RTA1 view of data</a>

<a	name="hw_tw"/>
<h3>2.2: integer Instructions: word / halfword / thirdword select</h3>

Please see also <a href="checkli.html">RTA1 view of data</a>

<p>
Application instructions have, quite separately from the bit-stream-channels,
direct access to octets and to 12-bit halfwords as well as the containing data
word. Integer instructions optionally select a byte, sign-extend on read, and
write to storage from the low-order positions of the register

<p>
Because RTA is designed to run without operand cache, there is an obvious
question, how shall the hardware do thirdword- and halfword-writes? Memory is
accessed as words and bursts of words

<p>
A byte-write, even if it is implemented as a read-modify, saves a number of
instructions and saves occupying two registers. That's of gigantic value to
applications. Byte writes need not be memory-locked for SMPs because they
are not used in arbitration

<p>
Arbitration is the job of <a href="http://TimMilesCox.github.io/RTA/rta.html#ts">Test-and-Set</a> instruction

<p>
It's still better to structure your data in words, however the hardware
implements byte-writes. You save two thirds of your instructions

<p>
And for many applications, the perfect byte-size is... 24 bits 

<a	name="pixels_large"/>
<h3>2.3: UTF-32, pixels, large and small bytes</h3>
<p>
RTA1 distributes UTF-32 and optionally UTF-16 data at one character per 24-bit
data word

<p>
All UTF-32 code points may be represented in 24 bits

<p>
Bit-stream-channels and application library can process strings of UTF-16 and of
any-size characters from 1 to 24 bits at packed bit positions with an efficiency
of one instruction per character


<a	name="stackspace"/>
<h2>3: does the internal stack run out of space?</h2>

<a	name="structured_real"/>
<h3>3.1: structured realtime in the internal stack</h3>

Please see also the explanation <a href="howsthat.html">internal stack, how's that?</a>

<p>
This extract from <a href="language.html">Towards Compiler Languages for RTA1 Architecture</a>
describes internal stack use for two contrasting needs

<p>
The RTA1 internal stack is a register array for  realtime programming.

<p>
Realtime problem solving typically executes routines to a depth of between
four and eight nested subroutine calls, each with between two and six
parameter words in the stack

<p>
The internal stack contains around twice that much

<p>
Here a routine is called with two  parameter words on the internal stack
<pre>

  :                            242
00:000553 FCF003              +243      lc   ber_sequence_scan a snmp_rseq,,i
00:000554 F80004              +243
00:000555 FCF002              +243
00:000556 3E0755              +243
00:000557 38000F              +243
  :                            244


</pre>
There are also a return address and a stack walkback pointer in each call,
so the stack use in this  call is four words. The application can keep on
like this for a nested depth of 26 calls

<p>
If the the internal stack overflows, the guard interrupt removes the thread
from the switch list

<p>
If that problem has been avoided, all the operands in the instruction path
are in a register array, namely the internal stack

<p>
That's the realtime intention of RTA1

<p>
If applications need more stack, there is no solution in building  a
larger internal stack into RTA1. That would make task switch slower and
applications could still overflow the internal stack

<p>
Some kinds of processing are not realtime, and must go about things in
a different way

<a	name="recursion"/>
<h3>3.2 recursive programming and zero-net internal stack</h3>

<p>
Recursion is a programming technique popular especially in education circles. Some applications need it

<p>
Macro language supports net-zero internal stack demand applied to individual
routines within a program

<p>
$zero_stack subfunction applied to macro <a href="language.html#sequence">$head_near / $head_far</a> prevents a routine from holding any internal stack registers

<p>
Parameters and returned addresses are farmed to the external stack until it's time to return

<p>
<a href="language.html#sequence">$head_near/far</a> also claims dynamic variables on the internal stack and these can be claimed in the external stack xframe() instead

<p>
The addition of the <b>$zero_stack</b> keyword keeps the internal stack
pointer <b>sp</b> at the same place however many nested calls routines
with <b>$zero_stack</b> make to themselves or to each other

<pre>

$ masmx recursiv -ln
MASMX 7r3
3/recursiv.msm
*EOF*
  :                            1 	$path		freeware/RTA1/rta/def
  :                            2: 	$include	rta.def
  :                            3 	$path
  :                            4: 	$include	stack.def
  :                            5 
  :                            6 $(0:64)
  :                            7 
                                inwego	$head_near,$zero_stack	 params(one,	float	;
                                					two,	float	;
                                					three,	float)	;
                                							;
00:000040 FDFFF2              +12 				 xframe()
00:000041 2F000E              +12 
00:000042 38E000              +12 
00:000043 38E001              +12 
00:000044 87E002              +12 
00:000045 87E006              +12 
00:000046 87E00A              +12 
00:000047 780010              +13 	tp	16
00:000048 B60054              +14 	j	enough
00:000049 1F0010              +15 	dec	16
  :                            16 
00:00004A 4FE002              +17 	ql	one
00:00004B 77E006              +18 	fm	two
00:00004C 770100              +19 	fm	(0.875)
00:00004D 67E00A              +20 	fa	three
  :                            21 
00:00004E 8FE00A              +22 	lc	inwego	a,,float two,,float three,,float
00:00004F 8FE006              +22 
00:000050 8F0004              +22 
00:000051 FCF00C              +22 
00:000052 3E0040              +22 
00:000053 38000F              +22 
  :                            23 
  :                            24 enough
00:000054 9FE000              +25 	$ret
00:000055 FCE00E              +25 
00:000056 38000E              +25 
00:000057 350000              +25 
  :                            26 
  :                            27 	$do	$<256,$(0:256)
*EOF*
00:000100+400000E00000000000000000
:$(00):000040:000104 :$(46):000000:00000E 
recursiv.msm: object code 279 bytes: 0 errors: 0 undefined labels


</pre>
Routines constructed with <b>$zero_stack</b> can interact completely
with routines constructed without

<p>
The external stack pointer <b>fp</b> must point to the high-memory
end of a sufficient buffer

<p>
Call sequences constructed with the <b>c/lc</b> macro push the parameter
list onto the internal stack. This is not different if <b>$zero_stack</b>
is opted. The <b>lc</b> macro pushes twelve parameter
words and a walkback pointer, then calls the target routine, itself in
this example
<pre>

	.------>_________________________________________________________________
	|	|   floating parameter three					|
	|	|_______________|_______________|_______________|_______________|
	|	|   floating parameter two					|
	|	|_______________|_______________|_______________|_______________|
	|	|   floating parameter one 					|
	|	|_______________|_______________|_______________|_______________|
	._______| stack walkback| return address|
		|_______________|_______________|


</pre>
If there are no parameters, the <b>c/lc</b> macro does not push a walkback
pointer or pop it afterwards

<p>
A called routine with <b>$zero_stack</b> unloads the call frame that it expects.
Its <b>xframe()</b> is larger than otherwise by the size of the expected call frame

<p>
<b>xframe()</b> must be declared when <b>$zero_stack</b> is opted, even if
<b>xframe()</b> is otherwise void. <b>head_near/far</b> macro uses uppercase <b>-V</b>
option to highlight its path. masmx has not assigned <b>-VUOS</b> for itself
<pre>

                                inwego	$head_near,$zero_stack	 params(one,	float	;
                                					two,	float	;
                                					three,	float)	;
                                							;
Note: recursiv.msm Line 12: buy external $$xframe
00:000040 FDFFF2              +12 				 xframe()
00:000041 2F000E              +12 
Note: recursiv.msm Line 12: internal stack zero net demand
00:000042 38E000              +12 
00:000043 38E001              +12 
00:000044 87E002              +12 
00:000045 87E006              +12 
00:000046 87E00A              +12 


</pre>
The expected call frame is popped in four-word blocks per instruction,
and the parameter names are mapped to the external stack locations

<p>
Without <b>$zero_stack</b> the parameter names are mapped to their internal
stack locations

<p>
If variables are constructed in <b>scalars()</b> they are in the internal stack.
To flat-line the internal stack, dynamic variables must be in <b>xframe()</b>

<p>
The default behaviour of a <b>$zero_stack</b> routine before return is to
push the stack walkback word if parameters were expected and then to push
the return address. Because there is optional behaviour, a <b>$ret</b>
macro is supplied to match the <b>$head_near/far</b> macro
<pre>

  :                            23 
  :                            24 enough
Note: recursiv.msm Line 25: internal stack zero net demand
Note: recursiv.msm Line 25: parameter list walkback
00:000054 9FE000              +25 	$ret
Note: recursiv.msm Line 25: sell external $$xframe
00:000055 FCE00E              +25 
00:000056 38000E              +25 
Note: recursiv.msm Line 25: near return
00:000057 350000              +25 
  :                            26 


</pre>
<p>
Alternatively the <b>-S</b> flag opts to push all of the call frame back
into the internal stack. This mostly makes no difference, because <b>c/lc</b>
macro immediately frees the call frame by popping the walkback word onto the
internal stack pointer
<pre>

  :                            23 
  :                            24 enough
Note: recursiv.msm Line 25: internal stack zero net demand
Note: recursiv.msm Line 25: restore internal stack $$list -S
00:000054 8FE00A              +25 	$ret
00:000055 8FE006              +25 
00:000056 8FE002              +25 
00:000057 9FE000              +25 
Note: recursiv.msm Line 25: sell external $$xframe
00:000058 FCE00E              +25 
00:000059 38000E              +25 
Note: recursiv.msm Line 25: near return
00:00005A 350000              +25 
  :                            26 


</pre
<p>
A difference which <b>-S</b> option does make is that changes which the called
routine makes inside its parameters are written back to the internal stack,
which is also the effect without <b>$zero_stack</b>

<p>
That might be an unorthodox way of passing results which are otherwise passed
in arithmetic registers <b>a:b:mantissa2:mantissa3</b>

<p>
<b>-S</b> restore to the internal stack can also paint over some accidental damage
where a routine has not been given the correct internal stack frame in the first place.
The <b>$zero_stack</b> routine pops the call frame it thinks it has.

<p>
The internal stack may underflow. The guard interrupt then isolates the wrong call
at this point

<p>
Otherwise <b>sp</b> points some words below (address-wise above) the stack top.
Further call and push activity now overwrites previously stacked words energetically.
If the called <b>$zero_stack</b> routine has <i>not</i> written to its copied
parameters in the external stack frame, the complete restore may undo one consequence
of a problem. If this makes a difference, it should only be done diagnostically and
not used to bring faulty code into service. The parameters which the <b>$zero_stack</b>
routine thinks it has are not the intended parameters until the real problem is fixed

<p>
<i>For the accompanying discussion <b>Trapping Wrong Argument Lists</b> please see
the accompanying document <a href="language.html#trapping">Towards Compiler Languages for RTA1 Architecture</a></i>
</i>

<a	name="proswip"/>
<h2>4. does RTA1 switch context quickly?</h2>

Process or thread switch takes slightly less or more than 105 instructions

<i>
<pre>

_______________________________________________________________________________________


LICENCE NOTE

    Copyright Tim Cox, 2012
    TimMilesCox@gmx.ch

    This document is part of the RTA1 Processor Programmable Architecture.

    RTA1 is a free processor architecture specification. It is licensed
    under the GNU General Public Licence Version 3

    The executable emulation of RTA1 is free software.

    Instruction code for the target RTA1 architecture is free software
    if it is delivered with this software

    Software programs delivered with this software to connect the
    emulated RTA1 with real network interfaces in the emulator host
    are free software

    Scripts and programs delivered with this software for running
    on other computers and interacting with the RTA1 are free software

    Scripts and utility programs for constructing RTA1 target
    executable software are free software

    You can redistribute it and/or modify RTA1
    under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    RTA1 is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with RTA1.  If not, see &lt;http://www.gnu.org/licenses/&gt;.


</pre>
</i>


</div>
</html

